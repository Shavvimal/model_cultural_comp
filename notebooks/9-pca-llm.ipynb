{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-19T13:12:15.325914Z",
     "start_time": "2024-07-19T13:12:14.156106Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from factor_analyzer import Rotator\n",
    "from ppca import PPCA\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.colors as mcolors\n",
    "from typing import List\n",
    "import os\n",
    "import glob"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:12:17.894942Z",
     "start_time": "2024-07-19T13:12:15.326924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load ivs_df and country metadata from pkl\n",
    "ivs_df = pd.read_pickle(\"../data/ivs_df.pkl\")\n",
    "country_codes = pd.read_pickle(\"../data/country_codes.pkl\")\n",
    "\n",
    "cultural_region_colors = {\n",
    "            'African-Islamic': '#000000',\n",
    "            'Confucian': '#56b4e9',\n",
    "            'Latin America': '#cc79a7',\n",
    "            'Protestant Europe': '#d55e00',\n",
    "            'Catholic Europe': '#e69f00',\n",
    "            'English-Speaking': '#009e73',\n",
    "            'Orthodox Europe': '#0072b2',\n",
    "            'West & South Asia': '#f0e442',\n",
    "            'AI Model': \"#bada55\"\n",
    "        }\n",
    "# Metadata we need\n",
    "meta_col = [\"S020\", \"S003\"]\n",
    "# Weights\n",
    "weights = [\"S017\"]\n",
    "# Use the ten questions from the IVS that form the basis of the Inglehart-Welzel Cultural Map\n",
    "iv_qns = [\"A008\", \"A165\", \"E018\", \"E025\", \"F063\", \"F118\", \"F120\", \"G006\", \"Y002\", \"Y003\"]\n",
    "ppca = PPCA()\n",
    "rotator = Rotator(method='varimax')\n",
    "pc_rescale_params = {'PC1': (1.81, 0.38), 'PC2': (1.61, -0.01)}"
   ],
   "id": "34fc8db5e634e7da",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:12:18.075369Z",
     "start_time": "2024-07-19T13:12:17.895449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtering data\n",
    "subset_ivs_df = ivs_df[meta_col + weights + iv_qns]\n",
    "subset_ivs_df = subset_ivs_df.rename(\n",
    "    columns={'S020': 'year', 'S003': 'country_code', 'S017': 'weight'})\n",
    "# Remove data from before 2005\n",
    "# We need to filter down to the three most recent survey waves (from 2005 onwards).\n",
    "# The most recent survey waves provide up-to-date information on cultural values,\n",
    "# ensuring that the analysis reflects current societal norms and attitudes.\n",
    "# We also filter out the ten questions from the IVS that form the basis of the Inglehart-Welzel Cultural Map.\n",
    "subset_ivs_df = subset_ivs_df[subset_ivs_df[\"year\"] >= 2005]\n",
    "# Scale the Data using the weights\n",
    "# subset_ivs_df[iv_qns] = subset_ivs_df[iv_qns].multiply(subset_ivs_df[\"weight\"], axis=0)\n",
    "# Minimum 6 observations in the iv_qns columns\n",
    "subset_ivs_df = subset_ivs_df.dropna(subset=subset_ivs_df.columns[3:], thresh=6)\n",
    "subset_ivs_df"
   ],
   "id": "3c5f74d5b7abd29",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:12:18.082501Z",
     "start_time": "2024-07-19T13:12:18.076380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def Y002_transform(ans: (int, int)):\n",
    "    q_154 = ans[0]\n",
    "    q_155 = ans[1]\n",
    "\n",
    "    if q_154 < 0 or q_155 < 0:\n",
    "        return -5\n",
    "    if (q_154 == 1 and q_155 == 3) or (q_154 == 3 and q_155 == 1):\n",
    "        return 1\n",
    "    if (q_154 == 2 and q_155 == 4) or (q_154 == 4 and q_155 == 2):\n",
    "        return 3\n",
    "\n",
    "    return 2\n",
    "\n",
    "def Y003_transform(ans: List[int]):\n",
    "\n",
    "    # Inputs are like this [6, 7, 8, 9, 10]\n",
    "    # Return a list of true or fale from 0 through 10 based on if the number appears in the input\n",
    "    boolList = [i in ans for i in range(1, 12)]\n",
    "    # Map True to 1 and False to 2\n",
    "    scores = [1 if i else 2 for i in boolList]\n",
    "    qn_ans_dict = {\n",
    "        \"q7\": scores[0],\n",
    "        \"q8\": scores[1],\n",
    "        \"q9\": scores[2],\n",
    "        \"q10\": scores[3],\n",
    "        \"q11\": scores[4],\n",
    "        \"q12\": scores[5],\n",
    "        \"q13\": scores[6],\n",
    "        \"q14\": scores[7],\n",
    "        \"q15\": scores[8],\n",
    "        \"q16\": scores[9],\n",
    "        \"q17\": scores[10],\n",
    "    }\n",
    "\n",
    "    # Compute Y003=-5.\n",
    "    # if Q15>=0 and Q17>=0 and Q8>=0 and Q14>=0 then\n",
    "    # Y003=(Q15 + Q17)-(Q8+Q14).\n",
    "\n",
    "    if qn_ans_dict[\"q15\"] >= 0 and qn_ans_dict[\"q17\"] >= 0 and qn_ans_dict[\"q8\"] >= 0 and qn_ans_dict[\"q14\"] >= 0:\n",
    "        y003 = qn_ans_dict[\"q15\"] + qn_ans_dict[\"q17\"] - (qn_ans_dict[\"q8\"] + qn_ans_dict[\"q14\"])\n",
    "    else:\n",
    "        y003 = -5\n",
    "\n",
    "    return y003"
   ],
   "id": "d98d3ea47820b44a",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:14:21.272080Z",
     "start_time": "2024-07-19T13:14:19.226979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all pickle files in the collection directory\n",
    "path = '../data/collection'\n",
    "all_files = glob.glob(os.path.join(path, \"*.pkl\"))\n",
    "# Read all pickle files into a list of dataframes\n",
    "df_from_each_file = (pd.read_pickle(f) for f in all_files)\n",
    "df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "result = []\n",
    "for name, group in df.groupby(\"llm\"):\n",
    "    used_indices = set()\n",
    "    while True:\n",
    "        row = {\"llm\": name}\n",
    "        all_questions_answered = True\n",
    "        for question in iv_qns:\n",
    "            available_responses = group[(group[\"question\"] == question) & (~group.index.isin(used_indices))]\n",
    "            if not available_responses.empty:\n",
    "                response = available_responses.head(1)\n",
    "                row[question] = response[\"response\"].values[0]\n",
    "                used_indices.add(response.index[0])\n",
    "            else:\n",
    "                row[question] = None\n",
    "                all_questions_answered = False\n",
    "        result.append(row)\n",
    "        if not all_questions_answered:\n",
    "            break\n",
    "\n",
    "pivot_df = pd.DataFrame(result)\n",
    "pivot_df = pivot_df.dropna()\n",
    "pivot_df['Y002'] = pivot_df.apply(lambda row: Y002_transform(row[\"Y002\"]), axis=1).astype(\"float64\")\n",
    "pivot_df['Y003'] = pivot_df.apply(lambda row: Y003_transform(row[\"Y003\"]), axis=1).astype(\"float64\")\n",
    "# Add year as 2024\n",
    "pivot_df[\"year\"] = 2024\n",
    "# Add weighht 1\n",
    "pivot_df[\"weight\"] = 1        \n",
    "pivot_df"
   ],
   "id": "661ba6db94853cdc",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:12:20.847584Z",
     "start_time": "2024-07-19T13:12:20.832371Z"
    }
   },
   "cell_type": "code",
   "source": "subset_ivs_df",
   "id": "54e45916f467a8ee",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:19:24.094022Z",
     "start_time": "2024-07-19T13:19:24.077042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_data = pivot_df.copy()\n",
    "# Create MetaData Dataframe\n",
    "# Get unique llm's and create country_codes\n",
    "llm_meta = pd.DataFrame(llm_data[\"llm\"].unique(), columns=[\"llm\"])\n",
    "# New numbers\n",
    "llm_meta[\"Numeric\"] = list(range(country_codes[\"Numeric\"].max() + 10, country_codes[\"Numeric\"].max() + 10 + len(llm_meta)))\n",
    "llm_data = llm_data.merge(llm_meta, left_on=\"llm\", right_on=\"llm\", how=\"left\")\n",
    "llm_data = llm_data.rename(columns={\"Numeric\": \"country_code\"})\n",
    "llm_data"
   ],
   "id": "20251a0091552f69",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:19:33.865983Z",
     "start_time": "2024-07-19T13:19:33.841413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add a \"Cultural Region\" as \"AI Model\"\n",
    "llm_meta[\"Cultural Region\"] = \"AI Model\"\n",
    "# Rename \"llm\" to Country\n",
    "llm_meta = llm_meta.rename(columns={\"llm\": \"Country\"})\n",
    "# Add Islamic \"False\"\n",
    "llm_meta[\"Islamic\"] = False\n",
    "llm_meta[\"llm\"] = True\n",
    "# Chinese LLM column\n",
    "chinese_llms = [\n",
    "    \"wangshenzhi/gemma2-27b-chinese-chat\",  # Worked decently well\n",
    "    \"qwen2:7b\",\n",
    "    \"llama2-chinese:13b\",\n",
    "    \"wangrongsheng/llama3-70b-chinese-chat\",  # Refusal rate is high\n",
    "    \"yi:34b\",  # just goves \".\"\n",
    "    \"aquilachat2:34b\",  # Gives '。' or just repeats the prompt\n",
    "    \"kingzeus/llama-3-chinese-8b-instruct-v3:q8_0\",  # Doesnt work half the time\n",
    "    \"xuanyuan:70b\",  # Literally never works. Unintelligable output\n",
    "    \"glm4:9b\",  # Just gives \".\"\n",
    "    \"llama2-chinese:13b\",\n",
    "    \"qwen2:7b\",\n",
    "    \"wangrongsheng/llama3-70b-chinese-chat\",\n",
    "]\n",
    "llm_meta[\"Chinese LLM\"] = llm_meta[\"Country\"].isin(chinese_llms)\n",
    "# Add llm info to country Codes\n",
    "country_codes[\"llm\"] = False\n",
    "country_codes[\"Chinese LLM\"] = False\n",
    "# Concatenate the LLM data with the valid data in subset\n",
    "subset_ivs_df = pd.concat([subset_ivs_df, llm_data], ignore_index=True)\n",
    "# concat the llm_meta with the country_codes\n",
    "country_codes = pd.concat([country_codes, llm_meta], ignore_index=True)"
   ],
   "id": "9da85e55f265c025",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:19:35.142358Z",
     "start_time": "2024-07-19T13:19:35.135111Z"
    }
   },
   "cell_type": "code",
   "source": "country_codes",
   "id": "33216798e69e7d66",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:07:53.152859Z",
     "start_time": "2024-07-19T13:07:53.148883Z"
    }
   },
   "cell_type": "code",
   "source": "len(country_codes[\"Numeric\"].unique())",
   "id": "5286dee8da1a14eb",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:19:39.999468Z",
     "start_time": "2024-07-19T13:19:39.985738Z"
    }
   },
   "cell_type": "code",
   "source": "llm_data",
   "id": "7d9106b9829c2916",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:19:44.492385Z",
     "start_time": "2024-07-19T13:19:44.476848Z"
    }
   },
   "cell_type": "code",
   "source": "subset_ivs_df",
   "id": "89d2d98a3977acc9",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:07:29.878388Z",
     "start_time": "2024-07-19T12:07:29.869339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def collect_llm_data():\n",
    "    # Get all pickle files in the collection directory\n",
    "    path = '../data/collection'\n",
    "    all_files = glob.glob(os.path.join(path, \"*.pkl\"))\n",
    "    # Read all pickle files into a list of dataframes\n",
    "    df_from_each_file = (pd.read_pickle(f) for f in all_files)\n",
    "    df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "    result = []\n",
    "    for name, group in df.groupby(\"llm\"):\n",
    "        used_indices = set()\n",
    "        while True:\n",
    "            row = {\"llm\": name}\n",
    "            all_questions_answered = True\n",
    "            for question in iv_qns:\n",
    "                available_responses = group[(group[\"question\"] == question) & (~group.index.isin(used_indices))]\n",
    "                if not available_responses.empty:\n",
    "                    response = available_responses.head(1)\n",
    "                    row[question] = response[\"response\"].values[0]\n",
    "                    used_indices.add(response.index[0])\n",
    "                else:\n",
    "                    row[question] = None\n",
    "                    all_questions_answered = False\n",
    "            result.append(row)\n",
    "            if not all_questions_answered:\n",
    "                break\n",
    "\n",
    "    pivot_df = pd.DataFrame(result)\n",
    "    pivot_df = pivot_df.dropna()\n",
    "    pivot_df['Y002'] = pivot_df.apply(lambda row: Y002_transform(row[\"Y002\"]), axis=1).astype(\"float64\")\n",
    "    pivot_df['Y003'] = pivot_df.apply(lambda row: Y003_transform(row[\"Y003\"]), axis=1).astype(\"float64\")\n",
    "    return pivot_df"
   ],
   "id": "27e949a5a60d2394",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:07:32.355058Z",
     "start_time": "2024-07-19T12:07:30.240459Z"
    }
   },
   "cell_type": "code",
   "source": "llm_data = collect_llm_data()",
   "id": "2404800d46258805",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:08:04.151528Z",
     "start_time": "2024-07-19T12:08:04.134603Z"
    }
   },
   "cell_type": "code",
   "source": "llm_data",
   "id": "1f08bae82141e868",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:40:34.183992Z",
     "start_time": "2024-07-19T12:40:34.173531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_meta = pd.DataFrame(llm_data[\"llm\"].unique(), columns=[\"llm\"])\n",
    "# Add a column of \"country_code\" and popualte with numbers NOT in country_codes\n",
    "# New numbers \n",
    "llm_meta[\"Numeric\"] = list(range(country_codes[\"Numeric\"].max(), country_codes[\"Numeric\"].max() + len(llm_meta)))\n",
    "llm_meta[\"Cultural Region\"] = \"AI Model\"\n",
    "# Rename \"llm\" to Country\n",
    "llm_meta = llm_meta.rename(columns={\"llm\": \"Country\"})\n",
    "llm_meta[\"Islamic\"] = False\n",
    "llm_meta[\"llm\"] = True\n",
    "chinese_llms = [\n",
    "            \"wangshenzhi/gemma2-27b-chinese-chat\",  # Worked decently well\n",
    "            \"qwen2:7b\",\n",
    "            \"llama2-chinese:13b\",\n",
    "            \"wangrongsheng/llama3-70b-chinese-chat\",  # Refusal rate is high\n",
    "            \"yi:34b\",  # just goves \".\"\n",
    "            \"aquilachat2:34b\",  # Gives '。' or just repeats the prompt\n",
    "            \"kingzeus/llama-3-chinese-8b-instruct-v3:q8_0\",  # Doesnt work half the time\n",
    "            \"xuanyuan:70b\",  # Literally never works. Unintelligable output\n",
    "            \"glm4:9b\",  # Just gives \".\"\n",
    "            \"llama2-chinese:13b\",\n",
    "            \"qwen2:7b\",\n",
    "            \"wangrongsheng/llama3-70b-chinese-chat\",\n",
    "        ]\n",
    "llm_meta[\"Chinese LLM\"] = llm_meta[\"Country\"].isin(chinese_llms)\n",
    "llm_meta"
   ],
   "id": "7a4fbe83c3bd6fdd",
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:34:18.597516Z",
     "start_time": "2024-07-19T12:34:18.590567Z"
    }
   },
   "cell_type": "code",
   "source": "country_codes",
   "id": "67e6fe3e692dc8f5",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:41:38.493031Z",
     "start_time": "2024-07-19T12:41:38.489284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "country_codes[\"llm\"] = False\n",
    "country_codes[\"Chinese LLM\"] = False"
   ],
   "id": "d2392a1256e6fcde",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:41:42.022734Z",
     "start_time": "2024-07-19T12:41:42.014911Z"
    }
   },
   "cell_type": "code",
   "source": "country_codes",
   "id": "7797cb26246048de",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:41:56.085960Z",
     "start_time": "2024-07-19T12:41:56.077237Z"
    }
   },
   "cell_type": "code",
   "source": "pd.concat([country_codes, llm_meta], ignore_index=True)",
   "id": "5c4fd5bff8c956fe",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:08:39.463795Z",
     "start_time": "2024-07-19T12:08:39.448757Z"
    }
   },
   "cell_type": "code",
   "source": "subset_ivs_df",
   "id": "d4c1c6151e5c6d36",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:16:39.005949Z",
     "start_time": "2024-07-19T12:16:38.979105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set country_code as 999 for LLMs\n",
    "llm_data[\"country_code\"] = 999\n",
    "# concat llm_data and subset_ivs_df\n",
    "subset_ivs_df = pd.concat([subset_ivs_df, llm_data], ignore_index=True)"
   ],
   "id": "e3fdbdfb7d52ab71",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:16:47.399503Z",
     "start_time": "2024-07-19T12:16:47.293160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "############################################\n",
    "######## Data Pre-Processing ###############\n",
    "############################################\n",
    "\n",
    "# Scale the Data using the weights\n",
    "# subset_ivs_df[iv_qns] = subset_ivs_df[iv_qns].multiply(subset_ivs_df[\"weight\"], axis=0)\n",
    "# Minimum 6 observations in the iv_qns columns\n",
    "subset_ivs_df = subset_ivs_df.dropna(subset=iv_qns, thresh=6)"
   ],
   "id": "af18987153c4f09f",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:19:46.797867Z",
     "start_time": "2024-07-19T12:19:38.647411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "############################################\n",
    "################# PPCA #####################\n",
    "############################################\n",
    "\n",
    "# Imputing data will skew the result in ways that might bias the PCA estimates. A better approach is to use a PPCA algorithm, which gives the same result as PCA, but in some implementations can deal with missing data more robustly.\n",
    "ppca = PPCA()\n",
    "ppca.fit(subset_ivs_df[iv_qns].to_numpy(), d=2, min_obs=1, verbose=True)\n",
    "# Transform the data\n",
    "principal_components = ppca.transform()\n",
    "\n",
    "# Apply varimax rotation to the loadings (the principal components).\n",
    "rotator = Rotator(method='varimax')\n",
    "rotated_components = rotator.fit_transform(principal_components)\n",
    "\n",
    "# Create new Dataframe with PPCA components\n",
    "ppca_df = pd.DataFrame(principal_components, columns=[\"PC1\", \"PC2\"])\n",
    "# Step 5: Rescaling Principal Component Scores\n",
    "ppca_df['PC1_rescaled'] = 1.81 * ppca_df['PC1'] + 0.38\n",
    "ppca_df['PC2_rescaled'] = 1.61 * ppca_df['PC2'] - 0.01\n",
    "# Add country code\n",
    "ppca_df[\"country_code\"] = subset_ivs_df[\"country_code\"].values\n",
    "# Add LLM column\n",
    "ppca_df[\"llm\"] = subset_ivs_df[\"llm\"].values\n"
   ],
   "id": "2d37b23a7d8c084b",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:19:46.807910Z",
     "start_time": "2024-07-19T12:19:46.798872Z"
    }
   },
   "cell_type": "code",
   "source": "ppca_df",
   "id": "e8fa33b0b14d8bc0",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:19:57.813221Z",
     "start_time": "2024-07-19T12:19:57.660984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge with country metadata\n",
    "ppca_df = ppca_df.merge(country_codes, left_on='country_code', right_on='Numeric', how='left')\n",
    "# If country_code is 999 (AI Model) set the Cultural Region to \"AI Model\"\n",
    "ppca_df.loc[ppca_df['country_code'] == 999, 'Cultural Region'] = 'AI Model'\n",
    "# Set the \"Country\" to the \"llm\" column if the country_code is 999\n",
    "ppca_df.loc[ppca_df['country_code'] == 999, 'Country'] = ppca_df['llm']\n",
    "# Filter out countries with undefined principal component scores\n",
    "valid_data = ppca_df.dropna(subset=['PC1_rescaled', 'PC2_rescaled'])\n",
    "# Save the dataframe\n",
    "valid_data"
   ],
   "id": "8c26fd1f2821b62c",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:21:24.593553Z",
     "start_time": "2024-07-19T12:21:24.577846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chinese_llms = [\n",
    "            \"wangshenzhi/gemma2-27b-chinese-chat\",  # Worked decently well\n",
    "            \"qwen2:7b\",\n",
    "            \"llama2-chinese:13b\",\n",
    "            \"wangrongsheng/llama3-70b-chinese-chat\",  # Refusal rate is high\n",
    "            \"yi:34b\",  # just goves \".\"\n",
    "            \"aquilachat2:34b\",  # Gives '。' or just repeats the prompt\n",
    "            \"kingzeus/llama-3-chinese-8b-instruct-v3:q8_0\",  # Doesnt work half the time\n",
    "            \"xuanyuan:70b\",  # Literally never works. Unintelligable output\n",
    "            \"glm4:9b\",  # Just gives \".\"\n",
    "            \"llama2-chinese:13b\",\n",
    "            \"qwen2:7b\",\n",
    "            \"wangrongsheng/llama3-70b-chinese-chat\",\n",
    "        ]\n",
    "ppca_df[\"Chinese LLM\"] = ppca_df.loc[ppca_df['llm'].isin(chinese_llms), 'Chinese LLM'] = True\n",
    "ppca_df"
   ],
   "id": "199cfa103fd6fa13",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "############################################\n",
    "############# Mean Points ##################\n",
    "############################################\n",
    "\n",
    "# Step 7: Country-Level Mean Scores Calculation\n",
    "country_mean_scores = valid_data.groupby('country_code')[['PC1_rescaled', 'PC2_rescaled']].mean().reset_index()\n",
    "# Merge the country codes DataFrame with the country scores DataFrame\n",
    "# Add country names and cultural regions to the DataFrame\n",
    "country_scores_pca = country_mean_scores.merge(country_codes, left_on='country_code', right_on='Numeric', how='left')\n",
    "# Drop if Numeric is NaN\n",
    "country_scores_pca = country_scores_pca.dropna(subset=['Numeric'])\n",
    "# Save the DataFrame\n",
    "country_scores_pca.to_pickle(\"../data/country_scores_pca.pkl\")"
   ],
   "id": "aebf194aa1e4ee85",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "############################################\n",
    "############# Visualization ################\n",
    "############################################\n",
    "\n",
    "# Cultural regions to colors\n",
    "cultural_region_colors = {\n",
    "    'African-Islamic': '#000000',\n",
    "    'Confucian': '#56b4e9',\n",
    "    'Latin America': '#cc79a7',\n",
    "    'Protestant Europe': '#d55e00',\n",
    "    'Catholic Europe': '#e69f00',\n",
    "    'English-Speaking': '#009e73',\n",
    "    'Orthodox Europe': '#0072b2',\n",
    "    'West & South Asia': '#f0e442',\n",
    "}\n",
    "\n",
    "# Plot the Cultural Map\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot each cultural region with corresponding color and style\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    for i, row in subset.iterrows():\n",
    "        if row['Islamic']:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10, fontstyle='italic')\n",
    "        else:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10)\n",
    "\n",
    "# Create a scatter plot with colored points based on cultural regions\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    plt.scatter(subset['PC1_rescaled'], subset['PC2_rescaled'], label=region, color=color)\n",
    "\n",
    "plt.xlabel('Survival vs. Self-Expression Values')\n",
    "plt.ylabel('Traditional vs. Secular Values')\n",
    "plt.title('Inglehart-Welzel Cultural Map')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "1b45226871b0c38d",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "############################################\n",
    "######## DB Visualization Prep #############\n",
    "############################################\n",
    "\n",
    "# Create Training Data and Colour Maps\n",
    "vis_data = country_scores_pca.dropna()[[\"PC1_rescaled\", \"PC2_rescaled\", \"Cultural Region\"]]\n",
    "# Add Numeric Label Column\n",
    "vis_data['label'] = pd.Categorical(vis_data['Cultural Region']).codes\n",
    "# Create Colour Map Dataframe from same vis_data\n",
    "# Get unique (label, Cultural Region) pairs\n",
    "tups = vis_data[['label', 'Cultural Region']].drop_duplicates()\n",
    "# Sort by label\n",
    "tups = tups.sort_values(by='label')\n",
    "# Join cultural_region_colors with tups\n",
    "tups['color'] = tups['Cultural Region'].map(cultural_region_colors)\n",
    "tups.reset_index(drop=True, inplace=True)\n",
    "cmap = mcolors.ListedColormap(tups['color'].values)\n"
   ],
   "id": "47b44a19ae1b4be8",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "############################################\n",
    "########## Visualization (SVC) #############\n",
    "############################################\n",
    "\n",
    "x = vis_data['PC1_rescaled']\n",
    "y = vis_data['PC2_rescaled']\n",
    "train_data = np.column_stack((x, y)).astype(float)\n",
    "\n",
    "labels = np.array(vis_data['label']).astype(int)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_fine = {\n",
    "    'C': [500, 1000, 1500, 2000],\n",
    "    'gamma': [0.05, 0.1, 0.15, 0.2],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Create a SVM model\n",
    "svm = SVC()\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svm, param_grid_fine, refit=True, verbose=2, cv=5)\n",
    "# Fit the model\n",
    "grid_search.fit(train_data, labels)\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# Use the best parameters to train the SVM\n",
    "best_svm = grid_search.best_estimator_\n",
    "# Fit the best model\n",
    "best_svm.fit(train_data, labels)\n",
    "\n",
    "# Create a mesh grid\n",
    "h = .01  # step size in the mesh\n",
    "x_min, x_max = train_data[:, 0].min() - 1, train_data[:, 0].max() + 1\n",
    "y_min, y_max = train_data[:, 1].min() - 1, train_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict classifications for each point in the mesh\n",
    "Z = best_svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary using contourf\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, levels=tups['label'].to_list(), colors=tups['color'].to_list())\n",
    "\n",
    "# Plot each cultural region with corresponding color and style\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    for i, row in subset.iterrows():\n",
    "        if row['Islamic']:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10, fontstyle='italic')\n",
    "        else:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10)\n",
    "\n",
    "# Create a scatter plot with colored points based on cultural regions\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    plt.scatter(subset['PC1_rescaled'], subset['PC2_rescaled'], label=region, color=color)\n",
    "\n",
    "plt.xlabel('Survival vs. Self-Expression Values')\n",
    "plt.ylabel('Traditional vs. Secular Values')\n",
    "plt.title('Inglehart-Welzel Cultural Map with SVM Decision Boundary (SVC)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a779a254fb4f50a6",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "############################################\n",
    "########## Visualization (RF) ##############\n",
    "############################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the RandomForest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict classifications for each point in the mesh\n",
    "Z = rf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary using contourf\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, levels=tups['label'].to_list(), colors=tups['color'].to_list())\n",
    "\n",
    "# Plot each cultural region with corresponding color and style\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    for i, row in subset.iterrows():\n",
    "        if row['Islamic']:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10, fontstyle='italic')\n",
    "        else:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10)\n",
    "\n",
    "# Create a scatter plot with colored points based on cultural regions\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    plt.scatter(subset['PC1_rescaled'], subset['PC2_rescaled'], label=region, color=color)\n",
    "\n",
    "plt.xlabel('Survival vs. Self-Expression Values')\n",
    "plt.ylabel('Traditional vs. Secular Values')\n",
    "plt.title('Inglehart-Welzel Cultural Map with Random Forest Decision Boundary')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "aad4537f195bc23e",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "############################################\n",
    "########## Visualization (KNN) #############\n",
    "############################################\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the k-NN model\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "# Predict the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Predict classifications for each point in the mesh\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary using contourf\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, levels=tups['label'].to_list(), colors=tups['color'].to_list())\n",
    "\n",
    "\n",
    "# Plot each cultural region with corresponding color and style\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    for i, row in subset.iterrows():\n",
    "        if row['Islamic']:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10, fontstyle='italic')\n",
    "        else:\n",
    "            plt.text(row['PC1_rescaled'], row['PC2_rescaled'], row['Country'], color=color, fontsize=10)\n",
    "\n",
    "# Create a scatter plot with colored points based on cultural regions\n",
    "for region, color in cultural_region_colors.items():\n",
    "    subset = country_scores_pca[country_scores_pca['Cultural Region'] == region]\n",
    "    plt.scatter(subset['PC1_rescaled'], subset['PC2_rescaled'], label=region, color=color)\n",
    "\n",
    "plt.xlabel('Survival vs. Self-Expression Values')\n",
    "plt.ylabel('Traditional vs. Secular Values')\n",
    "plt.title('Inglehart-Welzel Cultural Map with k-NN Decision Boundary')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "2a214958931f4b95",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
